"""
Download Dataset Module pentru Melanom AI
==========================================
Script pentru descÄƒrcarea È™i organizarea dataset-ului de imagini dermatoscopice
"""

import os
import shutil
import requests
import zipfile
from pathlib import Path
from typing import Optional, List
from tqdm import tqdm
import random
import yaml


def load_config(config_path: str = "config/config.yaml") -> dict:
    """ÃncarcÄƒ configuraÈ›ia din fiÈ™ierul YAML"""
    with open(config_path, 'r', encoding='utf-8') as f:
        return yaml.safe_load(f)


def download_file(url: str, destination: str, chunk_size: int = 8192) -> None:
    """
    DescarcÄƒ un fiÈ™ier de la URL
    
    Args:
        url: URL-ul fiÈ™ierului
        destination: Calea de destinaÈ›ie
        chunk_size: Dimensiunea chunk-ului pentru descÄƒrcare
    """
    response = requests.get(url, stream=True)
    total_size = int(response.headers.get('content-length', 0))
    
    with open(destination, 'wb') as f:
        with tqdm(total=total_size, unit='iB', unit_scale=True, desc="DescÄƒrcare") as pbar:
            for chunk in response.iter_content(chunk_size=chunk_size):
                if chunk:
                    f.write(chunk)
                    pbar.update(len(chunk))


def extract_zip(zip_path: str, extract_to: str) -> None:
    """
    Extrage un arhivÄƒ ZIP
    
    Args:
        zip_path: Calea cÄƒtre arhiva ZIP
        extract_to: Directorul de extragere
    """
    print(f"Extragere arhivÄƒ: {zip_path}")
    with zipfile.ZipFile(zip_path, 'r') as zip_ref:
        zip_ref.extractall(extract_to)
    print("Extragere completÄƒ!")


def create_directory_structure(base_path: str = ".") -> None:
    """
    CreeazÄƒ structura de directoare pentru dataset
    
    Args:
        base_path: Calea de bazÄƒ a proiectului
    """
    directories = [
        "data/raw/benign",
        "data/raw/malignant",
        "data/processed/benign",
        "data/processed/malignant",
        "data/train/benign",
        "data/train/malignant",
        "data/validation/benign",
        "data/validation/malignant",
        "data/test/benign",
        "data/test/malignant",
        "models",
        "logs",
        "results"
    ]
    
    for dir_path in directories:
        full_path = os.path.join(base_path, dir_path)
        os.makedirs(full_path, exist_ok=True)
        print(f"âœ“ Creat: {full_path}")
    
    print("\nStructura de directoare creatÄƒ cu succes!")


def split_dataset(source_dir: str,
                  train_dir: str,
                  val_dir: str,
                  test_dir: str,
                  train_ratio: float = 0.7,
                  val_ratio: float = 0.15,
                  test_ratio: float = 0.15,
                  seed: int = 42) -> dict:
    """
    Ãmparte dataset-ul Ã®n train/validation/test
    
    Args:
        source_dir: Directorul sursÄƒ cu imaginile
        train_dir: Directorul pentru date de antrenare
        val_dir: Directorul pentru date de validare
        test_dir: Directorul pentru date de test
        train_ratio: Procentul pentru antrenare
        val_ratio: Procentul pentru validare
        test_ratio: Procentul pentru test
        seed: Seed pentru reproducibilitate
    
    Returns:
        DicÈ›ionar cu statisticile Ã®mpÄƒrÈ›irii
    """
    random.seed(seed)
    stats = {}
    
    for class_name in ['benign', 'malignant']:
        class_source = os.path.join(source_dir, class_name)
        
        if not os.path.exists(class_source):
            print(f"âš  Directorul {class_source} nu existÄƒ!")
            continue
        
        # ObÈ›ine lista de fiÈ™iere
        files = [f for f in os.listdir(class_source) 
                 if f.lower().endswith(('.jpg', '.jpeg', '.png', '.bmp'))]
        
        if not files:
            print(f"âš  Nu s-au gÄƒsit imagini Ã®n {class_source}")
            continue
        
        # AmestecÄƒ fiÈ™ierele
        random.shuffle(files)
        
        # CalculeazÄƒ indicii de Ã®mpÄƒrÈ›ire
        n_files = len(files)
        n_train = int(n_files * train_ratio)
        n_val = int(n_files * val_ratio)
        
        train_files = files[:n_train]
        val_files = files[n_train:n_train + n_val]
        test_files = files[n_train + n_val:]
        
        # CopiazÄƒ fiÈ™ierele
        for file_list, dest_base in [(train_files, train_dir),
                                      (val_files, val_dir),
                                      (test_files, test_dir)]:
            dest_dir = os.path.join(dest_base, class_name)
            os.makedirs(dest_dir, exist_ok=True)
            
            for f in tqdm(file_list, desc=f"Copiere {class_name} -> {os.path.basename(dest_base)}"):
                src = os.path.join(class_source, f)
                dst = os.path.join(dest_dir, f)
                shutil.copy2(src, dst)
        
        stats[class_name] = {
            'total': n_files,
            'train': len(train_files),
            'validation': len(val_files),
            'test': len(test_files)
        }
    
    return stats


def print_dataset_stats(stats: dict) -> None:
    """
    AfiÈ™eazÄƒ statisticile dataset-ului
    
    Args:
        stats: DicÈ›ionarul cu statistici
    """
    print("\n" + "="*50)
    print("ğŸ“Š STATISTICI DATASET")
    print("="*50)
    
    total_train = 0
    total_val = 0
    total_test = 0
    
    for class_name, class_stats in stats.items():
        print(f"\nğŸ“ {class_name.upper()}")
        print(f"   Total: {class_stats['total']}")
        print(f"   Train: {class_stats['train']} ({class_stats['train']/class_stats['total']*100:.1f}%)")
        print(f"   Validation: {class_stats['validation']} ({class_stats['validation']/class_stats['total']*100:.1f}%)")
        print(f"   Test: {class_stats['test']} ({class_stats['test']/class_stats['total']*100:.1f}%)")
        
        total_train += class_stats['train']
        total_val += class_stats['validation']
        total_test += class_stats['test']
    
    total = total_train + total_val + total_test
    print(f"\nğŸ“ˆ TOTAL")
    print(f"   Total imagini: {total}")
    print(f"   Train: {total_train}")
    print(f"   Validation: {total_val}")
    print(f"   Test: {total_test}")


def verify_dataset_integrity(data_dir: str) -> bool:
    """
    VerificÄƒ integritatea dataset-ului
    
    Args:
        data_dir: Directorul de date
    
    Returns:
        True dacÄƒ dataset-ul este valid
    """
    print("\nğŸ” Verificare integritate dataset...")
    
    required_dirs = [
        "train/benign", "train/malignant",
        "validation/benign", "validation/malignant",
        "test/benign", "test/malignant"
    ]
    
    all_valid = True
    
    for dir_path in required_dirs:
        full_path = os.path.join(data_dir, dir_path)
        if os.path.exists(full_path):
            n_files = len([f for f in os.listdir(full_path) 
                          if f.lower().endswith(('.jpg', '.jpeg', '.png'))])
            status = "âœ“" if n_files > 0 else "âš "
            print(f"   {status} {dir_path}: {n_files} imagini")
            if n_files == 0:
                all_valid = False
        else:
            print(f"   âœ— {dir_path}: LIPSEÈ˜TE")
            all_valid = False
    
    return all_valid


def main():
    """FuncÈ›ia principalÄƒ pentru descÄƒrcarea È™i organizarea dataset-ului"""
    
    print("="*60)
    print("ğŸ”¬ MELANOM AI - DESCÄ‚RCARE È˜I ORGANIZARE DATASET")
    print("="*60)
    
    # CreeazÄƒ structura de directoare
    print("\nğŸ“ Creare structurÄƒ directoare...")
    create_directory_structure()
    
    print("\n" + "="*60)
    print("ğŸ“ INSTRUCÈšIUNI PENTRU DESCÄ‚RCAREA DATASET-ULUI")
    print("="*60)
    print("""
Pentru a descÄƒrca dataset-ul, urmeazÄƒ aceÈ™ti paÈ™i:

1. OPÈšIUNEA 1 - ISIC Archive (Recomandat):
   - AcceseazÄƒ: https://www.isic-archive.com/
   - CreeazÄƒ un cont gratuit
   - DescarcÄƒ imaginile din secÈ›iunea "Gallery"
   - OrganizeazÄƒ-le Ã®n data/raw/benign È™i data/raw/malignant

2. OPÈšIUNEA 2 - Kaggle:
   - AcceseazÄƒ: https://www.kaggle.com/datasets/kmader/skin-cancer-mnist-ham10000
   - DescarcÄƒ dataset-ul HAM10000
   - Extrage È™i organizeazÄƒ imaginile

3. OPÈšIUNEA 3 - Kaggle Competition:
   - AcceseazÄƒ: https://www.kaggle.com/c/siim-isic-melanoma-classification
   - DescarcÄƒ dataset-ul de competiÈ›ie

DupÄƒ descÄƒrcare, plaseazÄƒ imaginile Ã®n:
   - data/raw/benign/     (pentru leziuni benigne)
   - data/raw/malignant/  (pentru melanom/maligne)

Apoi ruleazÄƒ din nou acest script pentru a Ã®mpÄƒrÈ›i datele.
""")
    
    # VerificÄƒ dacÄƒ existÄƒ date Ã®n directorul raw
    raw_benign = "data/raw/benign"
    raw_malignant = "data/raw/malignant"
    
    has_benign = os.path.exists(raw_benign) and len(os.listdir(raw_benign)) > 0
    has_malignant = os.path.exists(raw_malignant) and len(os.listdir(raw_malignant)) > 0
    
    if has_benign and has_malignant:
        print("\nâœ“ S-au detectat imagini Ã®n directorul raw!")
        print("  Se va realiza Ã®mpÄƒrÈ›irea Ã®n train/validation/test...")
        
        # ÃncarcÄƒ configuraÈ›ia
        try:
            config = load_config()
            split_config = config.get('split', {})
        except:
            split_config = {}
        
        train_ratio = split_config.get('train_ratio', 0.7)
        val_ratio = split_config.get('validation_ratio', 0.15)
        test_ratio = split_config.get('test_ratio', 0.15)
        
        stats = split_dataset(
            source_dir="data/raw",
            train_dir="data/train",
            val_dir="data/validation",
            test_dir="data/test",
            train_ratio=train_ratio,
            val_ratio=val_ratio,
            test_ratio=test_ratio
        )
        
        print_dataset_stats(stats)
        
        # VerificÄƒ integritatea
        verify_dataset_integrity("data")
        
    else:
        print("\nâš  Nu s-au gÄƒsit imagini Ã®n directorul raw!")
        print("  UrmeazÄƒ instrucÈ›iunile de mai sus pentru a descÄƒrca dataset-ul.")


if __name__ == "__main__":
    main()
